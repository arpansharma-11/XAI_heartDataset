{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "import seaborn as sns\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "\n",
    "'''from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier  \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix'''\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('F:\\STUDY\\XAI\\HeartAttack Dataset'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "df=pd.read_csv('F:\\STUDY\\XAI\\HeartAttack Dataset/heart.csv')\n",
    "df.head()\n",
    "df.drop_duplicates(keep='first',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Set up the data for modelling \n",
    "# define Y \n",
    "y=df['output'].to_frame() \n",
    "# define X df.columns.difference removes the specified column\n",
    "X=df[df.columns.difference(['output'])] \n",
    " # create train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=101)\n",
    "\n",
    "\n",
    "\n",
    "# build model - Xgboost\n",
    "\n",
    "# build classifier\n",
    "xgb_mod=xgb.XGBClassifier(random_state=101, gpu_id=0, use_label_encoder = False)\n",
    "#values.ravel() compresses any array to 1D Array \n",
    "#print(y_train.values.ravel())\n",
    "xgb_mod=xgb_mod.fit(X_train,y_train.values.ravel())   \n",
    "\n",
    "print(xgb_mod)\n",
    "\n",
    "\n",
    "# make prediction and check model accuracy \n",
    "y_pred = xgb_mod.predict(X_test)\n",
    "\n",
    "print(y_test)\n",
    "unique, counts = np.unique(y_pred, return_counts=True)\n",
    "print(dict(zip(unique, counts)))\n",
    "print((y_pred))\n",
    "\n",
    "#probable question : What if we change the dataset to Influenza Dataset?\n",
    "\n",
    "# Performance\n",
    "#Actual Prediction Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "\n",
    "\n",
    "# Generate the Tree explainer and SHAP values\n",
    "explainer = shap.TreeExplainer(xgb_mod)\n",
    "shap_values = explainer.shap_values(X)\n",
    "expected_value = explainer.expected_value\n",
    "\n",
    "\n",
    "############## visualizations #############\n",
    "# Generate summary dot plot\n",
    "shap.summary_plot(shap_values, X,title=\"SHAP summary plot\") \n",
    "\n",
    "# Generate waterfall plot  \n",
    "shap.plots._waterfall.waterfall_legacy(expected_value, shap_values[79], features=X.loc[79,:], feature_names=X.columns, max_display=15, show=True)\n",
    "\n",
    "# Generate dependence plot\n",
    "shap.dependence_plot(\"thalachh\", shap_values, X, interaction_index=\"trtbps\")\n",
    "shap.dependence_plot(\"chol\", shap_values, X, interaction_index=\"trtbps\")\n",
    "shap.dependence_plot(\"restecg\", shap_values, X, interaction_index=\"trtbps\")\n",
    "shap.dependence_plot(\"oldpeak\", shap_values, X, interaction_index=\"trtbps\")\n",
    "\n",
    "# Generate force plot - Multiple rows \n",
    "shap.force_plot(explainer.expected_value, shap_values[:100,:], X.iloc[:100,:])\n",
    "\n",
    "# Generate force plot - Single\n",
    "shap.force_plot(explainer.expected_value, shap_values[0,:], X.iloc[0,:], matplotlib =True)\n",
    "\n",
    "\n",
    "shap.decision_plot(expected_value, shap_values[200],link='logit' ,features=X.loc[200,:], feature_names=(X.columns.tolist()),show=True,title=\"Decision Plot\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
